{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279b7afc-8cf8-4636-85d9-f276451dfe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100], dtype=int64))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate dataset\n",
    "x, y = make_classification(\n",
    "    n_samples=1000,          # Number of samples\n",
    "    n_features=10,           # Total number of features\n",
    "    n_informative=2,         # Number of informative features\n",
    "    n_redundant=8,           # Number of redundant features\n",
    "    n_classes=2,             # Number of classes\n",
    "    weights=[0.9, 0.1],      # Class weights\n",
    "    flip_y=0,                # Noise in labels\n",
    "    random_state=42          # Random state for reproducibility\n",
    ")\n",
    "\n",
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1bdf66-9f1a-4a44-834c-2e4460f3f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de84cfec-e8d6-4faa-9996-edc78e57c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Report (Dictionary):\n",
      " {'0': {'precision': 0.9510869565217391, 'recall': 0.9831460674157303, 'f1-score': 0.9668508287292817, 'support': 178.0}, '1': {'precision': 0.8125, 'recall': 0.5909090909090909, 'f1-score': 0.6842105263157895, 'support': 22.0}, 'accuracy': 0.94, 'macro avg': {'precision': 0.8817934782608696, 'recall': 0.7870275791624106, 'f1-score': 0.8255306775225356, 'support': 200.0}, 'weighted avg': {'precision': 0.9358423913043478, 'recall': 0.94, 'f1-score': 0.9357603954637976, 'support': 200.0}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define Logistic Regression with more parameters\n",
    "log_reg = LogisticRegression(\n",
    "    penalty='l2',           # L2 regularization\n",
    "    C=0.1,                  # Regularization strength\n",
    "    solver='liblinear',     # Optimization solver\n",
    "    max_iter=200,           # Maximum iterations\n",
    "    random_state=42         # Random state for reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log_reg = log_reg.predict(x_test)\n",
    "\n",
    "# Classification report as a dictionary\n",
    "log_reg_report = classification_report(y_test, y_pred_log_reg, output_dict=True)\n",
    "print(\"Logistic Regression Report (Dictionary):\\n\", log_reg_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23071e55-1929-42cc-8d32-bc26b9928513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Report (Dictionary):\n",
      " {'0': {'precision': 0.967391304347826, 'recall': 1.0, 'f1-score': 0.9834254143646409, 'support': 178.0}, '1': {'precision': 1.0, 'recall': 0.7272727272727273, 'f1-score': 0.8421052631578947, 'support': 22.0}, 'accuracy': 0.97, 'macro avg': {'precision': 0.9836956521739131, 'recall': 0.8636363636363636, 'f1-score': 0.9127653387612678, 'support': 200.0}, 'weighted avg': {'precision': 0.9709782608695652, 'recall': 0.97, 'f1-score': 0.9678801977318989, 'support': 200.0}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define Random Forest with more parameters\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,       # Number of trees\n",
    "    max_depth=10,           # Maximum depth of trees\n",
    "    min_samples_split=5,    # Minimum samples required to split an internal node\n",
    "    min_samples_leaf=2,     # Minimum samples required at a leaf node\n",
    "    bootstrap=True,         # Use bootstrap samples\n",
    "    random_state=42         # Random state for reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "# Classification report as a dictionary\n",
    "rf_report = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "print(\"Random Forest Report (Dictionary):\\n\", rf_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f541ddc8-c8ad-40a2-a853-1ed975641919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Report (Dictionary):\n",
      " {'0': {'precision': 0.9726775956284153, 'recall': 1.0, 'f1-score': 0.9861495844875346, 'support': 178.0}, '1': {'precision': 1.0, 'recall': 0.7727272727272727, 'f1-score': 0.8717948717948718, 'support': 22.0}, 'accuracy': 0.975, 'macro avg': {'precision': 0.9863387978142076, 'recall': 0.8863636363636364, 'f1-score': 0.9289722281412032, 'support': 200.0}, 'weighted avg': {'precision': 0.9756830601092896, 'recall': 0.975, 'f1-score': 0.9735705660913417, 'support': 200.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeke\\Downloads\\conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:24:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define XGBoost with default parameters\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,       # Number of boosting rounds\n",
    "    learning_rate=0.1,      # Learning rate\n",
    "    max_depth=6,            # Maximum tree depth\n",
    "    subsample=0.8,          # Subsample ratio of the training instance\n",
    "    colsample_bytree=0.8,   # Subsample ratio of columns when constructing each tree\n",
    "    random_state=42,        # Random state for reproducibility\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb.predict(x_test)\n",
    "\n",
    "# Classification report as a dictionary\n",
    "xgb_report = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "print(\"XGBoost Report (Dictionary):\\n\", xgb_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "429970fc-ba2f-4ca4-afc9-cc3532dc9dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost (Balanced Data) Report (Dictionary):\n",
      " {'0': {'precision': 0.9777777777777777, 'recall': 0.9887640449438202, 'f1-score': 0.9832402234636871, 'support': 178.0}, '1': {'precision': 0.9, 'recall': 0.8181818181818182, 'f1-score': 0.8571428571428571, 'support': 22.0}, 'accuracy': 0.97, 'macro avg': {'precision': 0.9388888888888889, 'recall': 0.9034729315628192, 'f1-score': 0.9201915403032721, 'support': 200.0}, 'weighted avg': {'precision': 0.9692222222222223, 'recall': 0.97, 'f1-score': 0.9693695131683958, 'support': 200.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeke\\Downloads\\conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:24:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Apply SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "x_train_balanced, y_train_balanced = smote_tomek.fit_resample(x_train, y_train)\n",
    "\n",
    "# Define XGBoost\n",
    "xgb_balanced = XGBClassifier(\n",
    "    n_estimators=150,       # Number of boosting rounds\n",
    "    learning_rate=0.05,     # Learning rate\n",
    "    max_depth=5,            # Maximum tree depth\n",
    "    subsample=0.9,          # Subsample ratio of the training instance\n",
    "    colsample_bytree=0.9,   # Subsample ratio of columns when constructing each tree\n",
    "    random_state=42,        # Random state for reproducibility\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Train the model on balanced data\n",
    "xgb_balanced.fit(x_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb_balanced = xgb_balanced.predict(x_test)\n",
    "\n",
    "# Classification report as a dictionary\n",
    "xgb_balanced_report = classification_report(y_test, y_pred_xgb_balanced, output_dict=True)\n",
    "print(\"XGBoost (Balanced Data) Report (Dictionary):\\n\", xgb_balanced_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72e59a6-c117-4921-abc5-c9d18e1df01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeke\\Downloads\\conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:24:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\beeke\\Downloads\\conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:24:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Apply SMOTETomek to balance the data\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "x_train_balanced, y_train_balanced = smote_tomek.fit_resample(x_train, y_train)\n",
    "\n",
    "# Define models with parameters\n",
    "models = [\n",
    "    (\n",
    "        'Logistic Regression',\n",
    "        LogisticRegression,\n",
    "        {'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'max_iter': 200, 'random_state': 42},\n",
    "        (x_train, y_train),\n",
    "        (x_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        'Random Forest',\n",
    "        RandomForestClassifier,\n",
    "        {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, \n",
    "         'bootstrap': True, 'random_state': 42},\n",
    "        (x_train, y_train),\n",
    "        (x_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        'XGBoost',\n",
    "        XGBClassifier,\n",
    "        {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 0.8, \n",
    "         'colsample_bytree': 0.8, 'random_state': 42, 'use_label_encoder': False, 'eval_metric': 'logloss'},\n",
    "        (x_train, y_train),\n",
    "        (x_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        'XGBoost (Balanced Data)',\n",
    "        XGBClassifier,\n",
    "        {'n_estimators': 150, 'learning_rate': 0.05, 'max_depth': 5, 'subsample': 0.9, \n",
    "         'colsample_bytree': 0.9, 'random_state': 42, 'use_label_encoder': False, 'eval_metric': 'logloss'},\n",
    "        (x_train_balanced, y_train_balanced),\n",
    "        (x_test, y_test)\n",
    "    )\n",
    "]\n",
    "\n",
    "report_final=[]\n",
    "# Train each model and print classification report\n",
    "for name, model_class, params, train_data, test_data in models:\n",
    "    x_train_model, y_train_model = train_data\n",
    "    x_test_model, y_test_model = test_data\n",
    "    \n",
    "    # Initialize the model with parameters\n",
    "    model = model_class(**params)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train_model, y_train_model)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x_test_model)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_test_model, y_pred, output_dict=True)\n",
    "    report_final.append(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd87072-3c50-4843-ac19-6218267188c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error setting experiment: Cannot set a deleted experiment 'anomaly_detection' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/13 14:25:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/0/runs/fab2329a2c834579a17326e289d9b5e8\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/13 14:25:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "C:\\Users\\beeke\\Downloads\\conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:25:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: http://127.0.0.1:5000/#/experiments/0/runs/bc52f561671145d9b724254ff1de5f26\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeke\\Downloads\\conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:25:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2024/12/13 14:25:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "C:\\Users\\beeke\\Downloads\\conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:25:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBoost at: http://127.0.0.1:5000/#/experiments/0/runs/2109c58a0d454298a665c75fec8f4628\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beeke\\Downloads\\conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:25:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2024/12/13 14:25:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBoost (Balanced Data) at: http://127.0.0.1:5000/#/experiments/0/runs/fca128ec58574445b6f9a6f72bfa3e4d\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow as mf\n",
    "\n",
    "# Set MLflow experiment and tracking URI\n",
    "experiment_name = 'anomaly_detection'\n",
    "mf.set_tracking_uri('http://127.0.0.1:5000')\n",
    "\n",
    "# Ensure the experiment exists and is correctly set\n",
    "try:\n",
    "    mf.set_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f\"Error setting experiment: {e}\")\n",
    "\n",
    "# Iterate over models and log parameters, metrics, and models to MLflow\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]         # Extract model name\n",
    "    model_class = element[1]        # Extract model class\n",
    "    params = element[2]             # Extract parameters\n",
    "    train_data = element[3]         # Extract train data\n",
    "    test_data = element[4]          # Extract test data\n",
    "    report = report_final[i]        # Extract classification report for the model\n",
    "\n",
    "    # Initialize the model with parameters\n",
    "    model = model_class(**params)\n",
    "    x_train_model, y_train_model = train_data\n",
    "    x_test_model, y_test_model = test_data\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train_model, y_train_model)\n",
    "    \n",
    "    # Log model details in MLflow\n",
    "    with mf.start_run(run_name=model_name):\n",
    "        # Log model name as a parameter\n",
    "        mf.log_param('model_name', model_name)\n",
    "\n",
    "        # Log all parameters of the model\n",
    "        for param_name, param_value in params.items():\n",
    "            mf.log_param(param_name, param_value)\n",
    "\n",
    "        # Log performance metrics\n",
    "        mf.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_0': report['0']['recall'],\n",
    "            'recall_1': report['1']['recall'],\n",
    "            'macro_f1_score': report['macro avg']['f1-score']\n",
    "        })\n",
    "\n",
    "        # Log the trained model\n",
    "        if 'XGB' in model_name:\n",
    "            mf.xgboost.log_model(model, 'model')\n",
    "        else:\n",
    "            mf.sklearn.log_model(model, 'model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f044676-5ff6-42e6-ad42-b24cf29ca959",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be450e80-bcd3-4a67-84cf-668305e3ec78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "model_name xgboost\n",
      "enter run id 62228c56cf13416f8d3f933d09961b6a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'xgboost' already exists. Creating a new version of this model...\n",
      "2024/12/13 14:26:56 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost, version 2\n",
      "Created version '2' of model 'xgboost'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow.xgboost\n",
    "\n",
    "model_name=input('model_name')\n",
    "run_id=input('enter run id')\n",
    "uri=f'runs:/{run_id}/model'\n",
    "result=mlflow.register_model(model_uri=uri,name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeafe48-8793-455e-a471-9c92358e74e3",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6b0dd9c-cf37-468e-9e57-1a4f92abf5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter model name xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b017e4289bcc44bab84258d29d7ebfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name=input('enter model name')\n",
    "model_version=1\n",
    "uri=f'models:/{model_name}@challenger'\n",
    "model=mlflow.xgboost.load_model(uri)\n",
    "y_pred_xg=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d320cf4e-415b-4265-a715-4b26c6847b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b3958-9967-42c4-a456-a85af609d98b",
   "metadata": {},
   "source": [
    "### Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec9a50f2-ca0f-48ff-b6a2-094ab289a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'xg123'.\n",
      "Copied version '1' of model 'xgboost' to version '1' of model 'xg123'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1734080562713, current_stage='None', description='', last_updated_timestamp=1734080562713, name='xg123', run_id='c5f1a586c1364e36bf9355d6cab1c229', run_link='', source='models:/xgboost/1', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri=f'models:/{model_name}@challenger'\n",
    "m_name='xg123'\n",
    "client=mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=uri,dst_name=m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4afde6ef-f27d-4528-be8c-c27bf3f7ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7c310953114e6e91c15123e70b12b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uri=f'models:/{m_name}@champion'\n",
    "model=mlflow.xgboost.load_model(uri)\n",
    "y_pred_xg_prod=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0902b035-55d0-4373-8095-53f509534cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xg_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ddcf5d-5dde-44c0-b7ca-275fafb31250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
